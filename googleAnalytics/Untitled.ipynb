{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from flask import Flask, jsonify, request\n",
    "import pandas as pd\n",
    "from flask import  render_template\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# https://www.tutorialspoint.com/flask\n",
    "import flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "def function_1(data_point):\n",
    "    \n",
    "    columns_to_be_considered = ['channelGrouping', 'date', 'fullVisitorId', 'visitId', 'visitNumber',\n",
    "       'visitStartTime', 'device.browser', 'device.operatingSystem',\n",
    "       'device.isMobile', 'device.deviceCategory', 'geoNetwork.continent',\n",
    "       'geoNetwork.subContinent', 'geoNetwork.country', 'geoNetwork.region',\n",
    "       'geoNetwork.metro', 'geoNetwork.city', 'geoNetwork.networkDomain',\n",
    "       'totals.hits', 'totals.pageviews', 'totals.timeOnSite',\n",
    "       'totals.sessionQualityDim', 'totals.transactions',\n",
    "       'totals.transactionRevenue', 'trafficSource.referralPath',\n",
    "       'trafficSource.campaign', 'trafficSource.source',\n",
    "       'trafficSource.medium', 'trafficSource.keyword',\n",
    "       'trafficSource.adContent', 'weekday', 'day', 'month', 'year', 'visitHour', 'is_weekend']\n",
    "    Data = pd.DataFrame(data_point,columns = columns_to_be_considered)\n",
    "#     print(Data.columns)\n",
    "    Data[\"date\"] = pd.to_datetime(Data[\"date\"])# seting the column as pandas datetime\n",
    "    Data[\"weekday\"] = Data['date'].dt.weekday #extra cting week day\n",
    "    Data[\"day\"] = Data['date'].dt.day # extracting day\n",
    "    Data[\"month\"] = Data['date'].dt.month # extracting month\n",
    "    Data[\"year\"] = Data['date'].dt.year # extracting year\n",
    "    Data['visitHour'] = (Data['visitStartTime'].apply(lambda x: str(datetime.fromtimestamp(x).hour))).astype(int) #instaed of this we could also use (pd.datetime(df['visitstarttime'], unit = 's').dt.hour\n",
    "    weekday_vals_t = Data['weekday'].values\n",
    "    weekend_t = []\n",
    "    for i in weekday_vals_t:\n",
    "        if (i == 0) or (i == 6):\n",
    "            weekend_t.append(1)\n",
    "        else:\n",
    "            weekend_t.append(0)\n",
    "    Data['is_weekend'] = weekend_t\n",
    "    \n",
    "    #     missing values noww\n",
    "    #     numerical values  \n",
    "    numerical_float_features = ['visitNumber','visitStartTime','totals.hits','totals.pageviews',\\\n",
    "                'totals.timeOnSite','totals.transactions','totals.transactionRevenue']\n",
    "    for i in numerical_float_features:\n",
    "        Data[i].fillna(0,inplace=True)\n",
    "        Data[i] = Data[i].astype('float')\n",
    "    print(\"float done       ........................\")\n",
    "\n",
    "    \n",
    "#     label_encoding\n",
    "    categorical_feat = ['channelGrouping','device.browser','device.operatingSystem','device.deviceCategory',\n",
    "                        'geoNetwork.continent','geoNetwork.subContinent','geoNetwork.country','geoNetwork.region',\n",
    "                        'geoNetwork.metro','geoNetwork.city','geoNetwork.networkDomain',\n",
    "                        'trafficSource.campaign','trafficSource.source','trafficSource.medium','trafficSource.keyword',\n",
    "                        'trafficSource.referralPath', 'trafficSource.adContent']\n",
    "    for feature in categorical_feat:\n",
    "    \n",
    "        label_encoder = preprocessing.LabelEncoder() \n",
    "        container = np.load(feature+'.npz')\n",
    "        data = [container[key] for key in container]\n",
    "        label_encoder.classes_ = data[0]     \n",
    "        a += 1\n",
    "        Data[feature]  = label_encoder.transform(list(Data[feature].values.astype('str')))\n",
    "    \n",
    "    print(\"categorical feature preprocessing done..!\")\n",
    "    \n",
    "\n",
    "\n",
    "# label encoding end\n",
    "\n",
    "    \n",
    "    test_frame_k_maxdate = max(Data['date'])\n",
    "    test_frame_k_mindate = min(Data['date'])\n",
    "    print(test_frame_k_maxdate)\n",
    "    print(test_frame_k_mindate)\n",
    "    print(type(test_frame_k_maxdate))\n",
    "    print(type(test_frame_k_mindate))\n",
    "    \n",
    "    test_frame_featurized = Data.groupby('fullVisitorId').agg({\n",
    "            'geoNetwork.networkDomain': [('networkDomain' , lambda x: x.dropna().max())], #max value of network domain\n",
    "            'geoNetwork.city':          [('city' , lambda x: x.dropna().max())],  #max value of city\n",
    "            'device.operatingSystem':   [('operatingSystem' , lambda x: x.dropna().max())],  #max value of Operating System\n",
    "            'geoNetwork.metro':         [('metro' , lambda x: x.dropna().max())],  #max value of metro\n",
    "            'geoNetwork.region':        [('region' , lambda x: x.dropna().max())],   #max vaue of region\n",
    "            'channelGrouping':          [('channelGrouping' , lambda x: x.dropna().max())],  #max value of channel grouping\n",
    "          'trafficSource.referralPath': [('referralPath' , lambda x: x.dropna().max())],  #max value of referral path\n",
    "            'geoNetwork.country':       [('country' , lambda x: x.dropna().max())],    #max value of country\n",
    "            'trafficSource.source':     [('source' , lambda x: x.dropna().max())],   #max value of source\n",
    "            'trafficSource.medium':     [('medium' , lambda x: x.dropna().max())],   #max value of medium\n",
    "            'trafficSource.keyword':    [('keyword', lambda x: x.dropna().max())], #max value of keyboard\n",
    "            'device.browser':           [('browser' , lambda x: x.dropna().max())],  #max value of browser\n",
    "            'device.deviceCategory':    [('deviceCategory', lambda x: x.dropna().max())], #max of device category\n",
    "            'geoNetwork.continent':     [('continent' , lambda x: x.dropna().max())],      #max of continent value\n",
    "            'geoNetwork.subContinent':  [('subcontinent' , lambda x: x.dropna().max())],  #max of sub_continent value\n",
    "            'totals.timeOnSite':        [('timeOnSite_sum'  , lambda x: x.dropna().sum()),     # total timeonsite of user\n",
    "                                         ('timeOnSite_min'  , lambda x: x.dropna().min()),     # min timeonsite\n",
    "                                         ('timeOnSite_max'  , lambda x: x.dropna().max()),     # max timeonsite\n",
    "                                         ('timeOnSite_mean' , lambda x: x.dropna().mean())],  # mean timeonsite\n",
    "            'weekday':                  [('weekday_min'  , lambda x: x.dropna().min()),     # min timeonsite\n",
    "                                         ('weekday_max'  , lambda x: x.dropna().max())],  # mean timeonsite\n",
    "            'day':                      [('day_min'  , lambda x: x.dropna().min()),     # min timeonsite\n",
    "                                         ('day_max'  , lambda x: x.dropna().max())],  # mean timeonsite\n",
    "            'month':                    [('month_min'  , lambda x: x.dropna().min()),     # min timeonsite\n",
    "                                         ('month_max'  , lambda x: x.dropna().max())],  # mean timeonsite\n",
    "            'year':                     [('year_min'  , lambda x: x.dropna().min()),     # min timeonsite\n",
    "                                         ('year_max'  , lambda x: x.dropna().max())],  # mean timeonsite\n",
    "            'visitHour':                [('visitHour_min'  , lambda x: x.dropna().min()),     # min timeonsite\n",
    "                                         ('visitHour_max'  , lambda x: x.dropna().max())],  # mean timeonsite\n",
    "            'totals.pageviews':         [('pageviews_sum'  , lambda x: x.dropna().sum()),     # total of page views\n",
    "                                         ('pageviews_min'  , lambda x: x.dropna().min()),     # min of page views\n",
    "                                         ('pageviews_max'  , lambda x: x.dropna().max()),     # max of page views\n",
    "                                         ('pageviews_mean' , lambda x: x.dropna().mean())],  # mean of page views\n",
    "            'totals.hits':              [('hits_sum'  , lambda x: x.dropna().sum()),     # total of hits\n",
    "                                         ('hits_min'  , lambda x: x.dropna().min()),     # min of hits\n",
    "                                         ('hits_max'  , lambda x: x.dropna().max()),     # max of hits\n",
    "                                         ('hits_mean' , lambda x: x.dropna().mean())],  # mean of hits\n",
    "            'visitStartTime':           [('visitStartTime_counts' , lambda x: x.dropna().count())], #Count of visitStartTime\n",
    "            'totals.sessionQualityDim': [('sessionQualityDim' , lambda x: x.dropna().max())], #Max value of sessionQualityDim\n",
    "            'device.isMobile':          [('isMobile' ,  lambda x: x.dropna().max())], #Max value of isMobile\n",
    "            'visitNumber':              [('visitNumber_max' , lambda x: x.dropna().max())],  #Maximum number of visits.\n",
    "            'totals.transactions' :     [('transactions' , lambda x:x.dropna().sum())], #Summation of all the transaction counts.\n",
    "            'date':                     [('first_ses_from_the_period_start' , lambda x: x.dropna().min() - test_frame_k_mindate), #first shopping session for customer after the period end date for current frame.\n",
    "                                         ('last_ses_from_the_period_end', lambda x: test_frame_k_maxdate - x.dropna().max()), #Last shopping session for customer before the period end date for current frame.\n",
    "                                         ('interval_dates' , lambda x: x.dropna().max() - x.dropna().min()),  #interval calculated as the latest date on which customer visited - oldest date on which they visited.\n",
    "                                         ('unqiue_date_num' , lambda x: len(set(x.dropna())))] , # Unique number of dates customer visited.           \n",
    "                                                         })\n",
    "    test_frame_featurized.columns = test_frame_featurized.columns.droplevel() \n",
    "    \n",
    "    test_frame_featurized['interval_dates'] = test_frame_featurized['interval_dates'].dt.days\n",
    "    test_frame_featurized['first_ses_from_the_period_start'] = test_frame_featurized['first_ses_from_the_period_start'].dt.days\n",
    "    test_frame_featurized['last_ses_from_the_period_end'] = test_frame_featurized['last_ses_from_the_period_end'].dt.days\n",
    "    \n",
    " \n",
    "    test_frame_featurized = test_frame_featurized.reset_index()\n",
    "\n",
    "    print(\"feature engineering process done..!\")\n",
    "    \n",
    "    return test_frame_featurized\n",
    "    \n",
    "@app.route('/')\n",
    "def hello_world():\n",
    "    return 'Hello World!'\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "@app.route('/index')\n",
    "def index():\n",
    "    return flask.render_template('index.html')\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "@app.route('/fun1', methods=['POST'])\n",
    "def fun1():\n",
    "    RF_classification_model = joblib.load('classifier_catboost_19.pkl')\n",
    "    data=[x for x in request.form.values()]\n",
    "    data_encoded=function_1(data)\n",
    "    \n",
    "    classification_pred  = RF_classification_model.predict(data_encoded.drop('fullVisitorId', axis=1))     \n",
    "\n",
    "    print(\"classoooo   doneeeee\")\n",
    "\n",
    "    RF_regression_model = joblib.load('Regressor_catboost_19.pkl') \n",
    "    \n",
    "    regression_pred      = RF_regression_model.predict(data_encoded.drop('fullVisitorId', axis=1))\n",
    "    \n",
    "    print('Regression Done...................')\n",
    "        \n",
    "    final_prediction     =  classification_pred*regression_pred\n",
    "    \n",
    "    print(\"prediction for query point done..!\")\n",
    "    \n",
    "    return final_prediction\n",
    "\n",
    "    return render_template('index.html',prediction_text=\"Prediction is {}\".format(prediction))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
